{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5553998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "# for dealing with raster data\n",
    "import rasterio as rs\n",
    "from rasterio.plot import show\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.mask import mask\n",
    "# Operating system tasks (e.g. checking if files exists)\n",
    "import os\n",
    "# for http requests\n",
    "import requests\n",
    "# allows to read data directly from the http request\n",
    "from io import BytesIO\n",
    "# for the shape file stuff (and sooo many other things)\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "import imageio\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import ee # Earth engine API\n",
    "import folium\n",
    "\n",
    "from itertools import chain, combinations\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from datetime import datetime, timedelta, UTC\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad3da96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ee_layer(self, ee_image_object, vis_params, name, show=True):\n",
    "    '''\n",
    "    For viewing the images in an interactive folium map\n",
    "    '''\n",
    "    map_id_dict = ee.Image(ee_image_object).getMapId(vis_params)\n",
    "    folium.raster_layers.TileLayer(\n",
    "        tiles=map_id_dict['tile_fetcher'].url_format,\n",
    "        attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
    "        name=name,\n",
    "        overlay=True,\n",
    "        control=True,\n",
    "        show=show\n",
    "    ).add_to(self)\n",
    "folium.Map.add_ee_layer = add_ee_layer\n",
    "\n",
    "def get_filter(unique_dict):\n",
    "    '''\n",
    "    builds an ee.Filter from the dictionary provided\n",
    "    '''\n",
    "    filter_list = [ee.Filter.eq(prop, j) for prop, j in unique_dict.items()]\n",
    "    return ee.Filter.And(*filter_list)\n",
    "\n",
    "def unpack_layer_name(nm):\n",
    "    '''\n",
    "    builds a dictionary from the layer name provided\n",
    "    can be passed directly to get_filter()\n",
    "    '''\n",
    "    nm_split = nm.split('_')\n",
    "    return {\n",
    "        \"relativeOrbitNumber_stop\": int(nm_split[0]),\n",
    "        \"sliceNumber\": int(nm_split[1]),\n",
    "        \"platform_number\": nm_split[2],\n",
    "        \"orbitProperties_pass\": nm_split[3],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5f9a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate by logging into your google acct\n",
    "#ee.Authenticate()\n",
    "# initialize the API\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202516ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Steps:\n",
    "\n",
    "1. General inquiry in area of interest (AOI)\n",
    "2. Plot each unique scene to test out different mosaic configurations\n",
    "3. Choose the mosaic configurations\n",
    "\n",
    "\n",
    "to cover the region of interest, need to pin down all of the:\n",
    "relativeOrbitNumber_stop, sliceNumber, platform_number, orbitProperties_pass\n",
    "\n",
    "'''\n",
    "gdf = gpd.read_file('shp/saglek_wide.shp', engine='fiona')\n",
    "#gdf = gpd.read_file('shp/nunatsiavut_coastline.shp', engine='fiona')\n",
    "gdf = gpd.read_file('shp/scott.shp', engine='fiona')\n",
    "#gdf = gpd.read_file('file:///Users/ccroberts/Applications/altimetryFit/shapes/cook_wide.shp', engine='fiona')\n",
    "aoi = ee.Geometry(gdf.geometry[0].__geo_interface__) # a large test region\n",
    "\n",
    "startDate, endDate = '2015-09-01', '2025-01-01' # short test window\n",
    "\n",
    "s1_ini = (\n",
    "    ee.ImageCollection('COPERNICUS/S1_GRD')\n",
    "    .filterBounds(aoi)\n",
    "    .filterDate(startDate, endDate)\n",
    "    .filter(ee.Filter.eq('instrumentMode', 'IW'))   # Interferometric Wide (IW, 10 m) swath or Extra Wide (EW, 40 m) swath\n",
    "    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'HH')).select('HH') # choose one: VV or HH\n",
    "    #.filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n",
    ").sort('system:time_start')\n",
    "\n",
    "print(f'{s1_ini.size().getInfo()} images found')\n",
    "print(f'Available Polarizations: {set(chain.from_iterable(s1_ini.aggregate_array('transmitterReceiverPolarisation').getInfo()))}')\n",
    "print(f' (note: ignore cross-polarization (HV, VH))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fc714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: define your metadata keys\n",
    "props = ['relativeOrbitNumber_stop', 'sliceNumber', 'platform_number', 'orbitProperties_pass']\n",
    "meta = props + ['system:time_start']\n",
    "\n",
    "# Step 2: get metadata from Earth Engine\n",
    "prop_values = {\n",
    "    key: s1_ini.aggregate_array(key).getInfo()\n",
    "    for key in meta\n",
    "}\n",
    "\n",
    "# Step 3: build image-wise metadata dictionaries\n",
    "s1_meta = [\n",
    "    {key: prop_values[key][i] for key in meta}\n",
    "    for i in range(len(prop_values[props[0]]))\n",
    "]\n",
    "\n",
    "# Step 4: group by the unique (orbit, slice, platform, pass)\n",
    "groups = defaultdict(list)\n",
    "for entry in s1_meta:\n",
    "    group_key = tuple(entry[key] for key in props)\n",
    "    groups[group_key].append(entry['system:time_start'])\n",
    "\n",
    "# Step 5: construct `s1_unique` with first and last timestamps\n",
    "props_unique = []\n",
    "for key, times in groups.items():\n",
    "    s1_entry = {prop: key[i] for i, prop in enumerate(props)}\n",
    "    times = sorted(times)\n",
    "    s1_entry['first_date'] = datetime.fromtimestamp(times[0]/1000, tz=UTC)\n",
    "    s1_entry['last_date'] = datetime.fromtimestamp(times[-1]/1000, tz=UTC)\n",
    "    s1_entry['count'] = len(times)\n",
    "    props_unique.append(s1_entry)\n",
    "\n",
    "# Optional: sort by time range (large to small)\n",
    "props_unique = sorted(\n",
    "    props_unique,\n",
    "    key=lambda d: d['last_date'] - d['first_date']\n",
    "    )[::-1]\n",
    "\n",
    "unique_filters = [get_filter({k: filt_dict[k] for k in props}) for filt_dict in props_unique]\n",
    "unique_imgs = [s1_ini.filter(filt).first() for filt in unique_filters]\n",
    "\n",
    "print(f'{len(unique_imgs)} unique images found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaafd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "center = aoi.centroid().getInfo()['coordinates'][::-1]\n",
    "f = folium.Figure(width=600, height=400)\n",
    "m = folium.Map(location=center, zoom_start=7).add_to(f)\n",
    "\n",
    "img = unique_imgs[0]\n",
    "available_bands = img.bandNames().getInfo()\n",
    "if 'VV' in available_bands and 'HH' in available_bands:\n",
    "    vizParams = {'min': -25, 'max': 0, 'bands': ['VV', 'HH']}\n",
    "elif 'VV' in available_bands:\n",
    "    vizParams = {'min': -25, 'max': 0, 'bands': ['VV']}\n",
    "elif 'HH' in available_bands:\n",
    "    vizParams = {'min': -25, 'max': 0, 'bands': ['HH']}\n",
    "else:\n",
    "    raise ValueError(\"No expected bands ('VV' or 'HH') found in image.\")\n",
    "\n",
    "for i, img in enumerate(unique_imgs):\n",
    "    nm = '_'.join(str(v) for v in [props_unique[i][prop] for prop in props])\n",
    "    count = props_unique[i]['count']\n",
    "    firstDate = props_unique[i]['first_date'].date()\n",
    "    lastDate = props_unique[i]['last_date'].date()\n",
    "    print(f'{nm}: {count} collected from {firstDate} to {lastDate}')\n",
    "    m.add_ee_layer(img, vizParams, name=nm, show=False)\n",
    "\n",
    "# Add the AOI polygon as a GeoJson layer\n",
    "folium.GeoJson(\n",
    "    data=aoi.getInfo(),\n",
    "    name='AOI',\n",
    "    style_function=lambda x: {\n",
    "        'color': 'blue',\n",
    "        'weight': 2,\n",
    "        'fillOpacity': 0.1\n",
    "    }\n",
    ").add_to(m)\n",
    "\n",
    "m.add_child(folium.LayerControl())\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e1cd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the layers that will make a nice mosaic (copy the layer names into layer_nms)\n",
    "# NB: Write the layers in the order you would like them to be place on the map (i.e. reverse order they are appear in layer_nms)\n",
    "# layer names: orbitNumber_sliceNumber_platform_passDirection (platform means sentinel-1A or sentinel-1B)\n",
    "# Note: as of 6/17/25, all tracks must be the same (orbitNumber and passDirection must be constant)\n",
    "layer_nms = ['120_1_B_ASCENDING', '120_2_B_ASCENDING', '149_2_B_ASCENDING', '149_3_B_ASCENDING'] # saglek_wide\n",
    "layer_nms = ['85_3_A_ASCENDING', '85_2_A_ASCENDING', '85_3_B_ASCENDING', '85_2_B_ASCENDING'] # scott glacier\n",
    "#layer_nms = ['10_6_A_ASCENDING', '10_5_A_ASCENDING', '10_6_B_ASCENDING', '10_5_B_ASCENDING'] # cook ice shelf\n",
    "\n",
    "mosaic_size = 2 # Number of images that make up a mosaic\n",
    "coverage_tol = 0.85 # fraction of image mosaic needs to cover (guesstimate based on map above)\n",
    "\n",
    "# Optionally, redefine mosaic parameters\n",
    "# startDate, endDate = '2015-01-01', '2030-01-01' \n",
    "# aoi = # optionally redefine the AOI \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8e7a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build gather metadata for each layer_nm\n",
    "\n",
    "# Example: {'10_5_A_ASCENDING': {'filter': ..., 'first': ..., 'last': ..., 'geometry': ...}}\n",
    "ic_dict = {nm: s1_ini.filter(get_filter(unpack_layer_name(nm))) for nm in layer_nms}\n",
    "\n",
    "filter_dict = {\n",
    "    nm: {\n",
    "        'filter': get_filter(unpack_layer_name(nm)),\n",
    "        'times': ic_dict[nm].aggregate_array('system:time_start').getInfo(),\n",
    "        'geom': ic_dict[nm].geometry()\n",
    "    }\n",
    "    for nm in layer_nms\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e62cace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by track first\n",
    "\n",
    "# Convert to shapely\n",
    "aoi_shape = shape(aoi.getInfo())\n",
    "for v in filter_dict.values():\n",
    "    v['shapely_geom'] = shape(v['geom'].getInfo())\n",
    "\n",
    "slice_groups = defaultdict(list)\n",
    "for i, nm in enumerate(layer_nms):\n",
    "    props = unpack_layer_name(nm)\n",
    "    key = (props['relativeOrbitNumber_stop'], props['platform_number'], props['orbitProperties_pass'])\n",
    "    slice_groups[key].append(nm)\n",
    "    \n",
    "combo_list = []\n",
    "# Assemble list of combos to assess\n",
    "for key in slice_groups.keys():\n",
    "    count = len(slice_groups[key])\n",
    "    combo = slice_groups[key]\n",
    "    if count > mosaic_size: \n",
    "        ## code to make new combos by adding how every many more elements necessary\n",
    "        ## creat combo_list\n",
    "        print('ERROR: not yet able to handle mosaics containing more than one track')\n",
    "        print('Select smaller aoi such that single tracks can cover the area')\n",
    "    elif count <= mosaic_size:\n",
    "        combo_list.append(tuple(combo))\n",
    "    else: \n",
    "        print('ERROR: unknown')\n",
    "\n",
    "coverage_sets = []\n",
    "for combo in combo_list:\n",
    "    union = unary_union([filter_dict[k]['shapely_geom'] for k in combo])\n",
    "    coverage = union.intersection(aoi_shape).area / aoi_shape.area\n",
    "    if coverage > coverage_tol:\n",
    "        # Intersect time ranges\n",
    "        print(combo)\n",
    "        start = max(filter_dict[k]['times'][0] for k in combo)\n",
    "        end = min(filter_dict[k]['times'][-1] for k in combo)\n",
    "        if start < end:\n",
    "            start_dt = datetime.fromtimestamp(start / 1000, tz=UTC).isoformat()\n",
    "            end_dt = datetime.fromtimestamp(end / 1000, tz=UTC).isoformat()\n",
    "            coverage_sets.append({'filter_keys': combo, 'start': start_dt, 'end': end_dt, 'coverage': round(float(coverage), 5)})\n",
    "\n",
    "print(f'Generated {len(coverage_sets)} sets with at least {coverage_tol*100} % coverage')\n",
    "coverage_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e85eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# might stop making a lot of sense from here\n",
    "\n",
    "\n",
    "# Align slices in each track\n",
    "tile_sets = []\n",
    "for s in coverage_sets:\n",
    "    s1a = {nm: ic_dict[nm] for nm in s['filter_keys']}\n",
    "    mission_ids = {i: s1a[i].aggregate_array('missionDataTakeID') for i in s1a}\n",
    "    mission = {i: list(mission_ids[i].getInfo()) for i in s1a}\n",
    "    common_ids = reduce(lambda a, b: a & b, [set(mission[i]) for i in s1a])\n",
    "    common_ids_ee = ee.List(list(common_ids))\n",
    "    s1a = {\n",
    "        i: s1a[i].filter(ee.Filter.inList('missionDataTakeID', common_ids_ee))\n",
    "        for i in s1a\n",
    "    }\n",
    "    tile_sets.append(s1a)\n",
    "    \n",
    "## put together mosaics for perfectly match collections of slices\n",
    "mosaics = []\n",
    "for tiles in tile_sets:\n",
    "    tiles = list(tiles.values())\n",
    "    img_lists = [col.toList(col.size()) for col in tiles]\n",
    "    n_imgs = img_lists[0].size().getInfo()\n",
    "    for i in range(n_imgs):\n",
    "        imgs = [ee.Image(lst.get(i)) for lst in img_lists]\n",
    "        mosaic = ee.ImageCollection(imgs).mosaic()\n",
    "        mosaic_clipped = mosaic.clip(aoi)\n",
    "        ts = imgs[0].get('system:time_start')  # or grab earliest if you want\n",
    "        mosaics.append(mosaic_clipped.set('system:time_start', ts))\n",
    "\n",
    "mosaic_ic = ee.ImageCollection(mosaics).sort('system:time_start')\n",
    "mosaics_sorted = mosaic_ic.toList(mosaic_ic.size())\n",
    "mosaics = [ee.Image(mosaics_sorted.get(i)) for i in range(mosaic_ic.size().getInfo())]\n",
    "dates = [datetime.fromtimestamp(ts / 1000, tz=UTC) for ts in mosaic_ic.aggregate_array('system:time_start').getInfo()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7937def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first n scenes to make sure it all went went\n",
    "n = 5\n",
    "\n",
    "center = aoi.centroid().getInfo()['coordinates'][::-1]\n",
    "m = folium.Map(location=center, zoom_start=7)\n",
    "\n",
    "\n",
    "available_bands = img.bandNames().getInfo()\n",
    "if 'VV' in available_bands and 'HH' in available_bands:\n",
    "    vizParams = {'min': -25, 'max': 0, 'bands': ['VV', 'HH']}\n",
    "elif 'VV' in available_bands:\n",
    "    vizParams = {'min': -25, 'max': 0, 'bands': ['VV']}\n",
    "elif 'HH' in available_bands:\n",
    "    vizParams = {'min': -25, 'max': 0, 'bands': ['HH']}\n",
    "else:\n",
    "    raise ValueError(\"No expected bands ('VV' or 'HH') found in image.\")\n",
    "\n",
    "for i, img in enumerate(mosaics[:n]):\n",
    "    nm = str(dates[i].date())\n",
    "    m.add_ee_layer(img, vizParams, name=nm)\n",
    "\n",
    "# Add the AOI polygon as a GeoJson layer\n",
    "folium.GeoJson(\n",
    "    data=aoi.getInfo(),\n",
    "    name='AOI',\n",
    "    style_function=lambda x: {\n",
    "        'color': 'blue',\n",
    "        'weight': 2,\n",
    "        'fillOpacity': 0.1\n",
    "    }\n",
    ").add_to(m)\n",
    "\n",
    "m.add_child(folium.LayerControl())\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc69fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = aoi  # ee.Geometry.Polygon(...)\n",
    "crs = 'EPSG:3031'\n",
    "\n",
    "def plot_frame(img):\n",
    "    \n",
    "    context_map = Image.open('scott_context.png')\n",
    "    context_np = np.array(context_map)    \n",
    "\n",
    "    # Get image date\n",
    "    date_str = img.date().format('YYYY-MM-dd').getInfo()\n",
    "\n",
    "    # Get thumbnail in correct CRS\n",
    "    url = img.getThumbURL({\n",
    "        'scale': 120, # 10 is native resolution, more like 50-70 may be good\n",
    "        'format': 'png',\n",
    "        'crs': crs,\n",
    "        'min': -25,\n",
    "        'max': 5,\n",
    "        'palette': ['black', 'white']  # or omit for grayscale\n",
    "    })\n",
    "\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        raise RuntimeError(f\"Thumbnail request failed with status {response.status_code}:\\n{response.text[:200]}\")\n",
    "    thumb = Image.open(BytesIO(response.content))\n",
    "\n",
    "    img_np = np.array(thumb)[:, :, 0]\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.imshow(img_np, cmap='gray')\n",
    "    #ax.set_title(date_str, fontsize=14, weight='bold')\n",
    "    ax.text(\n",
    "        0.02, 0.04, date_str,  # x, y in axes fraction (0â€“1)\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=10,\n",
    "        color='black',\n",
    "        bbox=dict(facecolor='white', edgecolor='black', boxstyle='square,pad=0.3', alpha=0.8)\n",
    "    )\n",
    "    ax.text(\n",
    "        0.98, 0.02, 'Imagery from Sentinel-1',  # x, y in axes fraction (bottom right)\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=6,\n",
    "        color='white',\n",
    "        ha='right', va='bottom',\n",
    "    )\n",
    "    \n",
    "    # Add context map inset in top-left\n",
    "    #inset_ax = fig.add_axes([0.14, 0.66, 0.13, 0.13])  # [left, bottom, width, height] # cook\n",
    "    inset_ax = fig.add_axes([0.77, 0.32, 0.13, 0.13])  # [left, bottom, width, height] # scott\n",
    "    inset_ax.imshow(context_np)\n",
    "    inset_ax.axis('off')\n",
    "    \n",
    "    ax.axis('off')\n",
    "    plt.close()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "fig = plot_frame(img)\n",
    "display(fig)\n",
    "\n",
    "#fig.savefig('/Users/ccroberts/Desktop/test_frame.png', dpi=500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b1a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gif_path = '~/Desktop/scott_movie.gif'\n",
    "\n",
    "\n",
    "# Temporary directory to store PNGs\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    frame_paths = []\n",
    "\n",
    "    for i, img in enumerate(mosaics):\n",
    "        print(f\"Processing img {i} of {len(mosaics)})\", end='\\r', flush=True)\n",
    "        fig = plot_frame(img)\n",
    "        frame_path = os.path.join(tmpdir, f'frame_{i:03d}.png')\n",
    "        fig.savefig(frame_path, dpi=500, bbox_inches='tight') # 150 for testing, 750 or 1000 for the final run (will take forever)\n",
    "        frame_paths.append(frame_path)\n",
    "\n",
    "    # Write to GIF\n",
    "    print('\\n Writing to gif')\n",
    "    with imageio.get_writer(gif_path, mode='I', duration=0.75) as writer:\n",
    "        for frame_path in frame_paths:\n",
    "            image = imageio.imread(frame_path)\n",
    "            writer.append_data(image)\n",
    "\n",
    "print(f\"Saved movie to {gif_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383cc188",
   "metadata": {},
   "outputs": [],
   "source": [
    "gif_path = '~/Desktop/scott_movie.gif'\n",
    "\n",
    "\n",
    "# Temporary directory to store PNGs\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    frame_paths = []\n",
    "\n",
    "    for i, img in enumerate(mosaics):\n",
    "        print(f\"Processing img {i} of {len(mosaics)})\", end='\\r', flush=True)\n",
    "        fig = None  # predefine to avoid UnboundLocalError\n",
    "        try:\n",
    "            fig = plot_frame(img)\n",
    "        except RuntimeError as e:\n",
    "            print(f\"\\nRetrying frame {i} due to error: {e}\")\n",
    "            try:\n",
    "                fig = plot_frame(img)\n",
    "            except RuntimeError as e2:\n",
    "                print(f\"Skipping frame {i} after second failure: {e2}\")\n",
    "        if fig is None:\n",
    "            continue  # skip to next image\n",
    "        frame_path = os.path.join(tmpdir, f'frame_{i:03d}.png')\n",
    "        fig.savefig(frame_path, dpi=500, bbox_inches='tight') # 150 for testing, 750 or 1000 for the final run (will take forever)\n",
    "        frame_paths.append(frame_path)\n",
    "\n",
    "    # Write to GIF\n",
    "    print('\\n Writing to gif')\n",
    "    with imageio.get_writer(gif_path, mode='I', duration=0.75) as writer:\n",
    "        for frame_path in frame_paths:\n",
    "            image = imageio.imread(frame_path)\n",
    "            writer.append_data(image)\n",
    "\n",
    "print(f\"Saved movie to {gif_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563d2c05",
   "metadata": {},
   "source": [
    "End of notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a307be7",
   "metadata": {},
   "source": [
    "### scratchwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b6c308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time sorting mosaicking \n",
    "\n",
    "# assemble the image collection for the movie\n",
    "s1_unique_fin = {i: unpack_layer_name(nm) for i, nm in enumerate(layer_nms)}\n",
    "unique_filters_fin = [get_filter(s1_unique_fin[i]) for i in s1_unique_fin]\n",
    "\n",
    "s1_fin = (\n",
    "    ee.ImageCollection('COPERNICUS/S1_GRD')\n",
    "    .filterBounds(aoi)\n",
    "    .filterDate(startDate, endDate)\n",
    "    .filter(ee.Filter.eq('instrumentMode', 'IW'))   # Interferometric Wide swath\n",
    "    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\n",
    "    .select('VV')  # or 'VH'\n",
    ").sort('system:time_start')\n",
    "\n",
    "s1_imgs_all = [s1_fin.filter(filt) for filt in unique_filters_fin]\n",
    "\n",
    "# group them by time_delta_days, drop scenes that are missing an image\n",
    "time_window_ms = time_delta_days * 24 * 60 * 60 * 1000  # in milliseconds\n",
    "\n",
    "# Get all images and their timestamps from each collection\n",
    "def get_images_and_times(ic):\n",
    "    imgs = ic.toList(ic.size())\n",
    "    timestamps = ic.aggregate_array('system:time_start').getInfo()\n",
    "    return imgs, timestamps\n",
    "\n",
    "def mosaic_clip(img_list, aoi):\n",
    "    ic = ee.ImageCollection(img_list)\n",
    "    mosaic = ic.mosaic()\n",
    "    mosaic_clipped = mosaic.clip(aoi)\n",
    "    return mosaic_clipped\n",
    "\n",
    "img_lists, time_lists = zip(*[get_images_and_times(c) for c in s1_imgs_all])\n",
    "\n",
    "# Count total images per collection\n",
    "initial_counts = [len(t) for t in time_lists]\n",
    "\n",
    "# Loop through reference (col0) and match from others\n",
    "scenes = []\n",
    "scene_dates = []\n",
    "for i0, t0 in enumerate(time_lists[0]):\n",
    "    center = t0\n",
    "    scene = [img_lists[0].get(i0)]\n",
    "\n",
    "    match_found = True\n",
    "    for j in range(len(layer_nms)):\n",
    "        diffs = [abs(t - center) for t in time_lists[j]]\n",
    "        min_diff = min(diffs)\n",
    "        if min_diff > time_window_ms:\n",
    "            match_found = False\n",
    "            break\n",
    "        min_index = diffs.index(min_diff)\n",
    "        scene.append(img_lists[j].get(min_index))\n",
    "\n",
    "    if match_found:\n",
    "        scenes.append(scene)\n",
    "        # Convert ms to UTC datetime for display\n",
    "        scene_dates.append(datetime.utcfromtimestamp(center / 1000).strftime('%Y-%m-%d'))\n",
    "\n",
    "scenes_clipped = [mosaic_clip(scene, aoi) for scene in scenes]\n",
    "\n",
    "# Print result\n",
    "print(f\"Matched scenes: {len(scenes)}\")\n",
    "for idx, (date, scene) in enumerate(zip(scene_dates, scenes)):\n",
    "    print(f\"Scene {idx+1}: {date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8530c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first n scenes to make sure it all went went\n",
    "n = 10\n",
    "\n",
    "center = aoi.centroid().getInfo()['coordinates'][::-1]\n",
    "m = folium.Map(location=center, zoom_start=7)\n",
    "\n",
    "# This will give an appropriate color scale for NDVI\n",
    "vizParams = {'min': -25, 'max': 0, 'bands': ['VV']}\n",
    "\n",
    "for i, img in enumerate(scenes_clipped[:n]):\n",
    "    nm = scene_dates[i]\n",
    "    m.add_ee_layer(img, vizParams, name=nm)\n",
    "\n",
    "# Add the AOI polygon as a GeoJson layer\n",
    "folium.GeoJson(\n",
    "    data=aoi.getInfo(),\n",
    "    name='AOI',\n",
    "    style_function=lambda x: {\n",
    "        'color': 'blue',\n",
    "        'weight': 2,\n",
    "        'fillOpacity': 0.1\n",
    "    }\n",
    ").add_to(m)\n",
    "\n",
    "m.add_child(folium.LayerControl())\n",
    "\n",
    "m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fresh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
